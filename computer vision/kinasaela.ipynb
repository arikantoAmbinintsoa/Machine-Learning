{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a8E7De68YVps",
      "metadata": {
        "id": "a8E7De68YVps"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "Travail individuel à réaliser par chaque étudiant. Chaque fichier devra ensuite être rassemblé par groupe dans le premier dépôt Git de l'année universitaire, dans un nouveau dossier nommé <code>Computer Vision</code>.\n",
        "\n",
        "Le nom du fichier doit être le prénom de l'étudiant écrit en minuscules. Par exemple, si l'étudiant s'appelle BOB Toto, le fichier doit être nommé toto.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wbgN6rm-N_tZ",
      "metadata": {
        "id": "wbgN6rm-N_tZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "K6EHkj63XsUy",
      "metadata": {
        "id": "K6EHkj63XsUy"
      },
      "source": [
        "# Détails de l'étudiant\n",
        "### Nom(s)  : RAZANAJATOVO ANDRIANIMERINA\n",
        "### Prénom(s) : Kinasaela\n",
        "### Classe : ESIIA 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Vision par Ordinateur avec Keras/TensorFlow : Un Notebook Pratique et Conceptuel\n",
        "\n",
        "Ce notebook a pour objectif de vous guider pas à pas dans la création et l'analyse d'un modèle de réseau de neurones convolutif (CNN) appliqué au jeu de données CIFAR-10. Chaque étape est accompagnée d'explications pratiques ainsi que de questions conceptuelles pour renforcer votre compréhension des enjeux théoriques et pratiques de la vision par ordinateur."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape1",
      "metadata": {
        "id": "etape1"
      },
      "source": [
        "## Étape 1 : Introduction et Configuration de l'Environnement\n",
        "\n",
        "Dans cette étape, nous allons configurer notre environnement de travail et importer les bibliothèques indispensables pour le deep learning et la manipulation de données. Nous vérifions également la version de TensorFlow pour nous assurer que tout fonctionne correctement.\n",
        "\n",
        "### Explication Pratique\n",
        "La bonne configuration de l'environnement est cruciale pour garantir la reproductibilité et la stabilité de vos expériences. En particulier, les versions des bibliothèques peuvent influencer le comportement du modèle et sa performance, d'où l'importance de vérifier et documenter ces versions dès le début."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "code-etape1",
        "outputId": "bb1339f0-25eb-4422-af7b-15b5088ed18a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Version de TensorFlow : 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# Importer les bibliothèques nécessaires\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Version de TensorFlow :', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question1",
      "metadata": {
        "id": "question1"
      },
      "source": [
        "### Question  1\n",
        "\n",
        "**Q1 :** Pourquoi est-il essentiel de vérifier la configuration de l'environnement (versions des bibliothèques, dépendances, etc.) avant de développer un modèle de deep learning ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZQE_C9KzTYhR",
      "metadata": {
        "id": "ZQE_C9KzTYhR"
      },
      "source": [
        "Vérifier la configuration de l’environnement, c’est super important pour la reproductibilité. Si on utilise exactement les mêmes versions des bibliothèques, on est sûr d’obtenir les mêmes résultats, que ce soit sur notre machine ou sur une autre. Sinon, un même code peut donner des résultats complètement différents.\n",
        "\n",
        "Toutes les versions des bibliothèques ne sont pas toujours compatibles entre elles. Par exemple, une nouvelle version de TensorFlow peut ne plus être compatible avec certaines fonctions de Keras. Si on ne fait pas attention, on peut se retrouver avec des erreurs difficiles à comprendre.\n",
        "\n",
        "La stabilité et la performance du modèle peuvent aussi dépendre des versions utilisées. Parfois, une mise à jour améliore les performances, mais elle peut aussi introduire des bugs. C’est pour ça qu’il vaut mieux s’assurer que tout fonctionne bien avant de commencer.\n",
        "\n",
        "Enfin, certaines bibliothèques ont des dépendances très spécifiques. Si on entraîne un modèle avec une version précise de TensorFlow, il se peut qu’il ne fonctionne plus correctement avec une version plus récente ou plus ancienne. Vérifier les versions permet donc d’éviter de mauvaises surprises."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape2",
      "metadata": {
        "id": "etape2"
      },
      "source": [
        "## Étape 2 : Chargement et Prétraitement des Données\n",
        "\n",
        "Nous allons charger le jeu de données CIFAR-10, composé de 60 000 images couleur réparties en 10 classes. Dans cette étape, nous normalisons les valeurs des pixels afin qu'elles soient comprises entre 0 et 1, et nous transformons les étiquettes en format one-hot pour faciliter le processus de classification.\n",
        "\n",
        "### Explication Pratique\n",
        "La normalisation aide à stabiliser et accélérer l'entraînement du modèle en assurant que les valeurs d'entrée ont une échelle comparable. Le one-hot encoding évite que le modèle interprète les étiquettes comme des valeurs numériques ordonnées, ce qui est essentiel pour les problèmes de classification multi-classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape2",
      "metadata": {
        "id": "code-etape2"
      },
      "outputs": [],
      "source": [
        "# Charger le jeu de données CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normaliser les valeurs des pixels (entre 0 et 1)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convertir les vecteurs de classes en matrices binaires (one-hot encoding)\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Forme des données d'entrainement :\", x_train.shape)\n",
        "print(\"Forme des étiquettes d'entraînement :\", y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question2",
      "metadata": {
        "id": "question2"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "**Q2 :** Expliquez comment la normalisation des pixels et le one-hot encoding des étiquettes contribuent chacun à la stabilité et à l'efficacité de l'entraînement d'un modèle de deep learning.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06nm5cklTg8J",
      "metadata": {
        "id": "06nm5cklTg8J"
      },
      "source": [
        "La normalisation des pixels et le one-hot encoding des étiquettes sont super importants pour que l'entraînement du modèle soit stable et efficace.  \n",
        "\n",
        "D’abord, la **normalisation des pixels** (diviser les valeurs par 255 pour les ramener entre 0 et 1) permet d’avoir des entrées sur une échelle cohérente. Si les valeurs des pixels allaient de 0 à 255, les poids du réseau devraient gérer des écarts trop grands, ce qui pourrait rendre l'entraînement instable et plus lent. En normalisant, on aide le modèle à converger plus rapidement et de manière plus fluide.  \n",
        "\n",
        "Ensuite, le **one-hot encoding** est utilisé pour éviter que le modèle interprète les classes comme des valeurs numériques continues. Par exemple, sans one-hot encoding, une classe \"3\" pourrait être vue comme plus proche de \"2\" que de \"7\", alors que ce ne sont que des catégories indépendantes. Avec cette technique, chaque classe est représentée par un vecteur binaire, ce qui facilite l’apprentissage et améliore les performances du modèle, surtout pour les problèmes de classification multi-classes comme CIFAR-10."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape3",
      "metadata": {
        "id": "etape3"
      },
      "source": [
        "## Étape 3 : Exploration et Visualisation des Données\n",
        "\n",
        "Avant de construire le modèle, il est important d'explorer et de visualiser les données. Nous affichons ainsi un échantillon d'images du jeu de données pour mieux comprendre leur contenu et la distribution des classes.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation des données permet d'identifier d'éventuelles anomalies, comme des classes sous-représentées ou des images bruitées, et de décider si des techniques d'augmentation de données ou de prétraitement supplémentaires sont nécessaires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape3",
      "metadata": {
        "id": "code-etape3"
      },
      "outputs": [],
      "source": [
        "# Afficher quelques images du jeu de données d'entraînement\n",
        "noms_classes = ['avion', 'automobile', 'oiseau', 'chat', 'cerf',\n",
        "               'chien', 'grenouille', 'cheval', 'navire', 'camion']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.xlabel(noms_classes[y_train[i].argmax()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question3",
      "metadata": {
        "id": "question3"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "**Q3 :** D'après la visualisation, discutez de l'impact potentiel d'une distribution inégale des classes ou de la présence d'images de mauvaise qualité sur la performance d'un modèle de classification. Quelles stratégies pourraient être mises en place pour pallier ces problèmes ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U2eV_0CeTnlj",
      "metadata": {
        "id": "U2eV_0CeTnlj"
      },
      "source": [
        "Si la distribution des classes dans le jeu de données est inégale, le modèle risque d’être biaisé. Par exemple, s’il y a beaucoup plus d’images d’\"automobiles\" et de \"camions\" que d’\"oiseaux\" ou de \"cerfs\", il apprendra mieux à reconnaître les classes majoritaires et ignorera les classes sous-représentées, ce qui entraînera une mauvaise généralisation. De plus, la présence d’images de mauvaise qualité, comme des images floues, mal cadrées ou bruitées, peut perturber l’apprentissage et réduire la capacité du modèle à bien classifier les nouvelles images. Pour pallier ces problèmes, plusieurs stratégies peuvent être mises en place.  \n",
        "\n",
        "Tout d’abord, il est possible de rééquilibrer les classes en augmentant artificiellement le nombre d’images sous-représentées grâce à l’augmentation de données, qui consiste à appliquer des transformations comme la rotation, le zoom ou le flip. On peut aussi réduire le nombre d’images des classes majoritaires ou encore utiliser des poids de classe lors de l’entraînement pour que le modèle prenne mieux en compte les classes rares. Ensuite, il est important de filtrer et améliorer les données en supprimant ou corrigeant les images de mauvaise qualité et en appliquant des techniques de prétraitement, comme le lissage ou la réduction du bruit. Enfin, une autre solution consiste à collecter plus de données afin d’équilibrer les classes et d’améliorer la diversité des exemples. En mettant en place ces stratégies, on s’assure que le modèle apprend de manière plus équitable et généralisera mieux sur de nouvelles données."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape4",
      "metadata": {
        "id": "etape4"
      },
      "source": [
        "## Étape 4 : Construction du Modèle CNN\n",
        "\n",
        "Nous allons construire un réseau de neurones convolutif (CNN) pour extraire des caractéristiques hiérarchiques des images. Ce modèle se compose de plusieurs blocs de convolution suivis de couches de pooling et se termine par des couches entièrement connectées pour la classification.\n",
        "\n",
        "### Explication Pratique\n",
        "Les couches de convolution permettent au modèle de détecter des motifs locaux (comme les contours ou les textures), tandis que les couches de pooling réduisent la dimensionnalité, ce qui diminue la charge computationnelle et aide à rendre le modèle plus robuste aux translations. Le dropout, quant à lui, est une technique de régularisation qui aide à prévenir le surapprentissage en désactivant aléatoirement certains neurones pendant l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape4",
      "metadata": {
        "id": "code-etape4"
      },
      "outputs": [],
      "source": [
        "# Construire le modèle CNN\n",
        "model = models.Sequential()\n",
        "\n",
        "# Bloc de convolution 1 : 32 filtres, taille 3x3, activation ReLU\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 2 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Bloc de convolution 3 : 64 filtres\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Aplatir les sorties et ajouter des couches entièrement connectées\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question4",
      "metadata": {
        "id": "question4"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "**Q4 :** Décrivez le rôle de chaque composant du CNN (couches de convolution, pooling et dropout) et expliquez comment ils interagissent pour permettre au modèle d'extraire des caractéristiques pertinentes des images.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dG3-Wa35XbTp",
      "metadata": {
        "id": "dG3-Wa35XbTp"
      },
      "source": [
        "Couches de convolution (Conv2D)\n",
        "- Elles appliquent des filtres aux images d’entrée pour détecter des motifs locaux (ex : contours, textures).  \n",
        "- Chaque filtre extrait une caractéristique spécifique.  \n",
        "- L’activation ReLU (Rectified Linear Unit) introduit de la non-linéarité pour permettre au modèle d’apprendre des relations complexes.  \n",
        "\n",
        "Couches de pooling (MaxPooling2D)\n",
        "- Elles réduisent la taille des cartes de caractéristiques, diminuant ainsi le nombre de paramètres et la charge computationnelle.  \n",
        "- Le pooling rend le modèle plus robuste aux petites variations et translations dans l’image.  \n",
        "- Dans le code, une fenêtre de taille (2,2) est utilisée pour extraire la valeur maximale dans chaque région, conservant ainsi les informations les plus importantes.  \n",
        "\n",
        "Aplatissement (Flatten)\n",
        "- Il transforme la sortie 2D des couches de convolution en un vecteur 1D pour pouvoir être utilisé par les couches entièrement connectées.  \n",
        "\n",
        "Couches entièrement connectées (Dense)\n",
        "- Elles combinent les caractéristiques extraites par les couches de convolution pour effectuer la classification finale.  \n",
        "- Une couche Dense avec 64 neurones et activation ReLU aide à apprendre des représentations plus complexes.  \n",
        "- La dernière couche Dense avec `softmax` attribue une probabilité à chaque classe pour effectuer la classification.  \n",
        "\n",
        "Dropout\n",
        "- Il désactive aléatoirement 50% des neurones pendant l’entraînement (`Dropout(0.5)`).  \n",
        "- Cela empêche le surapprentissage en forçant le réseau à ne pas dépendre excessivement de certaines connexions.  \n",
        "\n",
        "Interaction entre les composants\n",
        "1. Convolution → Pooling : Extraction des caractéristiques locales et réduction de la dimension.  \n",
        "2. Empilement des blocs convolutionnels : Apprentissage progressif des motifs de bas niveau (bords, textures) vers des motifs plus complexes.  \n",
        "3. Flatten → Dense : Transformation des caractéristiques en un vecteur utilisable pour la classification.  \n",
        "4. Dropout : Régularisation pour améliorer la généralisation.  \n",
        "5. Softmax : Attribution des probabilités aux différentes classes pour la prise de décision finale."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape5",
      "metadata": {
        "id": "etape5"
      },
      "source": [
        "## Étape 5 : Compilation et Entraînement du Modèle\n",
        "\n",
        "Nous allons maintenant compiler le modèle en choisissant un optimiseur, une fonction de perte ainsi que des métriques d'évaluation. Ensuite, nous entraînons le modèle sur les données d'entraînement en réservant une partie des données pour la validation.\n",
        "\n",
        "### Explication Pratique\n",
        "La compilation configure le processus d'apprentissage, notamment la manière dont les poids seront ajustés via la rétropropagation. Le choix de l'optimiseur (ici, Adam) et la définition des hyperparamètres (comme le taux d'apprentissage et la taille du batch) influencent grandement la vitesse de convergence et la qualité finale du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape5",
      "metadata": {
        "id": "code-etape5"
      },
      "outputs": [],
      "source": [
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question5",
      "metadata": {
        "id": "question5"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "**Q5 :** Quels sont les effets d'un choix inadapté d'hyperparamètres (comme le taux d'apprentissage ou la taille du batch) sur l'entraînement d'un réseau de neurones ? Expliquez en quoi un optimiseur bien configuré est crucial pour la convergence du modèle.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_JBZNfoFYQjt",
      "metadata": {
        "id": "_JBZNfoFYQjt"
      },
      "source": [
        "Un **taux d’apprentissage trop élevé** empêche la convergence, provoque des oscillations et peut mener à la divergence. Un **taux trop faible** ralentit l’apprentissage et peut bloquer le modèle dans un minimum local. Une **taille de batch trop grande** réduit la fréquence des mises à jour des poids, accélère l’entraînement mais risque une convergence sous-optimale. Une **taille de batch trop petite** augmente la variance des gradients, rendant l’optimisation plus bruitée et instable.\n",
        "\n",
        "L’**optimiseur Adam** ajuste dynamiquement le taux d’apprentissage, accélère la convergence et stabilise l’apprentissage. Il permet une mise à jour efficace des poids en combinant le momentum et l’adaptation du taux d’apprentissage. Un optimiseur mal configuré peut ralentir l’entraînement, provoquer un surajustement ou empêcher la convergence.\n",
        "\n",
        "Un bon paramétrage équilibre la **vitesse d’apprentissage**, la **stabilité** et la **généralisation** du modèle. L’**interaction entre le taux d’apprentissage, la taille du batch et l’optimiseur** est cruciale pour obtenir de bonnes performances."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape6",
      "metadata": {
        "id": "etape6"
      },
      "source": [
        "## Étape 6 : Évaluation du Modèle\n",
        "\n",
        "Après l'entraînement, nous évaluons notre modèle sur le jeu de test afin de mesurer sa capacité de généralisation sur des données inédites. Les métriques telles que la perte et la précision nous aident à quantifier la performance globale du modèle.\n",
        "\n",
        "### Explication Pratique\n",
        "L'évaluation sur un jeu de test indépendant permet de détecter un éventuel surapprentissage (overfitting). Si le modèle présente une bonne performance sur l'entraînement mais une performance médiocre sur le test, cela indique qu'il n'a pas suffisamment généralisé, ce qui peut nécessiter des ajustements comme plus de régularisation ou des techniques d'augmentation de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape6",
      "metadata": {
        "id": "code-etape6"
      },
      "outputs": [],
      "source": [
        "# Évaluer le modèle sur le jeu de test\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Précision sur le jeu de test :', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question6",
      "metadata": {
        "id": "question6"
      },
      "source": [
        "### Question  6\n",
        "\n",
        "**Q6 :** Que nous indiquent la perte et la précision obtenues lors de l'évaluation sur le jeu de test ? Quels ajustements pourriez-vous envisager si vous observez un écart significatif entre les performances sur l'entraînement et le test ?\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UIE8pJwzYpry",
      "metadata": {
        "id": "UIE8pJwzYpry"
      },
      "source": [
        "La **perte** indique combien le modèle se trompe dans ses prédictions, une valeur plus faible suggère une meilleure performance. La **précision** mesure le pourcentage de bonnes prédictions, une précision élevée sur le test signifie que le modèle généralise bien. Si la précision est élevée sur l'entraînement mais faible sur le test, cela indique un **surapprentissage**. Dans ce cas, vous pourriez ajuster le modèle en augmentant la **régularisation** (comme en augmentant le taux de dropout), en utilisant des techniques d’**augmentation de données** pour diversifier le jeu d'entraînement, ou en réduisant la **complexité du modèle** pour éviter qu’il n'apprenne des détails spécifiques à l’entraînement."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape7",
      "metadata": {
        "id": "etape7"
      },
      "source": [
        "## Étape 7 : Prédictions et Visualisation des Résultats\n",
        "\n",
        "Nous allons utiliser le modèle entraîné pour prédire les classes des images du jeu de test. La visualisation des résultats nous permet de comparer les étiquettes prédites aux étiquettes réelles et d'identifier les erreurs potentielles.\n",
        "\n",
        "### Explication Pratique\n",
        "La visualisation aide à comprendre qualitativement comment le modèle se comporte face à différentes images. Cela permet d'identifier si certaines classes sont systématiquement mal prédites ou si le modèle confond certaines catégories, ouvrant ainsi la voie à des améliorations ultérieures (par exemple, via l'augmentation de données ou des ajustements de l'architecture)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "code-etape7",
      "metadata": {
        "id": "code-etape7"
      },
      "outputs": [],
      "source": [
        "# Faire des prédictions sur le jeu de test\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Fonction pour afficher l'image avec les étiquettes prédites et réelles\n",
        "def afficher_image(i, predictions_array, etiquette_vraie, img):\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    etiquette_predite = np.argmax(predictions_array)\n",
        "    etiquette_vraie = np.argmax(etiquette_vraie)\n",
        "\n",
        "    couleur = 'blue' if etiquette_predite == etiquette_vraie else 'red'\n",
        "    plt.xlabel(f\"Prédit : {noms_classes[etiquette_predite]} (Vrai : {noms_classes[etiquette_vraie]})\", color=couleur)\n",
        "\n",
        "# Afficher quelques images de test avec leurs prédictions\n",
        "nb_lignes = 5\n",
        "nb_colonnes = 3\n",
        "nb_images = nb_lignes * nb_colonnes\n",
        "plt.figure(figsize=(2 * nb_colonnes, 2 * nb_lignes))\n",
        "for i in range(nb_images):\n",
        "    plt.subplot(nb_lignes, nb_colonnes, i+1)\n",
        "    afficher_image(i, predictions[i], y_test[i], x_test[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "question7",
      "metadata": {
        "id": "question7"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "**Q7 :** Après avoir examiné les prédictions, identifiez et discutez des stratégies conceptuelles (par exemple, l'augmentation de données, le raffinement de l'architecture ou l'ajustement des hyperparamètres) qui pourraient améliorer la robustesse et la précision du modèle.\n",
        "\n",
        "_Répondez dans une nouvelle cellule Markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Mk3pmEwY69-",
      "metadata": {
        "id": "2Mk3pmEwY69-"
      },
      "source": [
        "Après avoir examiné les prédictions, voici des stratégies possibles pour améliorer la robustesse et la précision du modèle :\n",
        "\n",
        "1. **Augmentation de données** : Si le modèle confond certaines classes ou a des difficultés avec certaines images, l’augmentation de données (rotation, zoom, décalage) peut aider à diversifier le jeu d’entraînement et améliorer la généralisation.\n",
        "\n",
        "2. **Raffinement de l'architecture** : Ajouter plus de couches convolutionnelles, augmenter la taille des filtres ou ajuster les hyperparamètres des couches existantes (par exemple, augmenter le nombre de filtres) peut permettre au modèle de mieux capturer des caractéristiques complexes des images.\n",
        "\n",
        "3. **Ajustement des hyperparamètres** : Expérimenter avec différents taux d'apprentissage, tailles de batch et le nombre d'époques pourrait permettre d'améliorer la convergence du modèle. Un ajustement fin de ces paramètres peut permettre au modèle de mieux généraliser.\n",
        "\n",
        "4. **Régularisation supplémentaire** : Si des erreurs de surapprentissage sont observées (précision élevée en entraînement mais faible en test), l’augmentation du dropout ou l’introduction de techniques comme la **L2 régularisation** pourrait être bénéfique pour réduire le surajustement.\n",
        "\n",
        "5. **Ensembles de modèles** : Combiner plusieurs modèles (par exemple, via le **bagging** ou le **boosting**) pourrait également améliorer la précision en réduisant la variance des prédictions.\n",
        "\n",
        "Ces stratégies devraient être testées pour évaluer leur impact sur les performances globales du modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "etape8",
      "metadata": {
        "id": "etape8"
      },
      "source": [
        "## Étape 8 : Conclusion et Travaux Futurs\n",
        "\n",
        "Dans ce notebook, nous avons :\n",
        "- Configuré l'environnement et importé les bibliothèques nécessaires\n",
        "- Chargé et prétraité le jeu de données CIFAR-10\n",
        "- Exploré et visualisé les données\n",
        "- Construit, compilé et entraîné un modèle CNN\n",
        "- Évalué le modèle et visualisé ses prédictions\n",
        "\n",
        "### Explication Pratique\n",
        "Ce pipeline offre une approche complète, à la fois pratique et conceptuelle, pour la mise en œuvre d'un modèle de vision par ordinateur. Pour aller plus loin, vous pouvez explorer des architectures plus complexes, appliquer des techniques d'augmentation de données ou encore expérimenter avec différents optimisateurs afin de mieux comprendre l'impact de chacun sur la performance du modèle."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
